{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28083983",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9d2a5fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>Depth</th>\n",
       "      <th>Mag</th>\n",
       "      <th>An</th>\n",
       "      <th>Previous</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57.090</td>\n",
       "      <td>-153.480</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60.000</td>\n",
       "      <td>-135.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>1901</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52.000</td>\n",
       "      <td>-160.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>1901</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51.450</td>\n",
       "      <td>-171.020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1901</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52.380</td>\n",
       "      <td>-167.450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363065</th>\n",
       "      <td>16.625</td>\n",
       "      <td>-98.755</td>\n",
       "      <td>35.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363066</th>\n",
       "      <td>52.788</td>\n",
       "      <td>171.431</td>\n",
       "      <td>48.4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363067</th>\n",
       "      <td>14.083</td>\n",
       "      <td>-92.184</td>\n",
       "      <td>62.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363068</th>\n",
       "      <td>-61.596</td>\n",
       "      <td>154.288</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363069</th>\n",
       "      <td>-6.950</td>\n",
       "      <td>154.485</td>\n",
       "      <td>52.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>363070 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Lat      Lon  Depth  Mag    An  Previous\n",
       "0       57.090 -153.480    0.0  8.3  1900         0\n",
       "1       60.000 -135.000    0.0  7.1  1901         0\n",
       "2       52.000 -160.000    0.0  6.6  1901         0\n",
       "3       51.450 -171.020    0.0  7.8  1901         0\n",
       "4       52.380 -167.450    0.0  7.8  1902         0\n",
       "...        ...      ...    ...  ...   ...       ...\n",
       "363065  16.625  -98.755   35.0  4.0  2012         0\n",
       "363066  52.788  171.431   48.4  4.5  2012         0\n",
       "363067  14.083  -92.184   62.4  4.4  2012         0\n",
       "363068 -61.596  154.288   10.0  5.2  2012         0\n",
       "363069  -6.950  154.485   52.8  4.6  2012         0\n",
       "\n",
       "[363070 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('C:/ProgramData/MySQL/MySQL Server 8.0/Uploads/Earthquake.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "618142e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[106.0991  75.7125  20.6023 167.8326]\n",
      "[[  57.09 -153.48    0.      8.3 ]\n",
      " [  60.   -135.      0.      7.1 ]\n",
      " [  52.   -160.      0.      6.6 ]\n",
      " [  51.45 -171.02    0.      7.8 ]]\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from numpy import set_printoptions\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "# load data\n",
    "\n",
    "\n",
    "array = df.values\n",
    "X = array[:,0:4]\n",
    "Y = array[:, 5]\n",
    "# feature extraction\n",
    "test = SelectKBest(score_func=f_classif, k= 'all')\n",
    "fit = test.fit(X, Y)\n",
    "# summarize scores\n",
    "set_printoptions(precision=4)\n",
    "print(fit.scores_)\n",
    "features = fit.transform(X)\n",
    "# summarize selected features\n",
    "print(features[0:4,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "444eb45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Global.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20cc7ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0.      57.09  -153.48     0.   ]\n",
      " [   0.      60.    -135.       0.   ]\n",
      " [   0.      52.    -160.       0.   ]\n",
      " ...\n",
      " [   0.      14.083  -92.184   62.4  ]\n",
      " [   0.     -61.596  154.288   10.   ]\n",
      " [   0.      -6.95   154.485   52.8  ]]\n"
     ]
    }
   ],
   "source": [
    "col1 = df[['Previous','Lat', 'Lon', 'Depth']]\n",
    "col2 = df['Mag']\n",
    "#Convert to Numpy array\n",
    "InputX1 = col1.to_numpy()\n",
    "InputY1 = col2.to_numpy()\n",
    "print(InputX1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d621981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mininum values: [0. 0.]\n",
      "Maximum values: [  4.  735.8]\n"
     ]
    }
   ],
   "source": [
    "X1_min = np.amin(InputX1,0)     \n",
    "X1_max = np.amax(InputX1,0)   \n",
    "print(\"Mininum values:\",X1_min)\n",
    "print(\"Maximum values:\",X1_max)\n",
    "Y1_min = np.amin(InputY1)     \n",
    "Y1_max = np.amax(InputY1) \n",
    "InputX1_norm = (InputX1-X1_min)/(X1_max-X1_min)\n",
    "InputY1_norm = InputY1  #No normalization in output\n",
    "\n",
    "#Reshape\n",
    "Xfeatures = 4 #Number of input features\n",
    "Yfeatures = 1 #Number of input features\n",
    "samples = 363070 # Number of samples\n",
    "\n",
    "InputX1_reshape = np.resize(InputX1_norm,(samples,Xfeatures))\n",
    "InputY1_reshape = np.resize(InputY1_norm,(samples,Yfeatures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfe1098d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2000\n",
    "InputX1train = InputX1_reshape[0:batch_size,:]\n",
    "InputY1train = InputY1_reshape[0:batch_size,:]\n",
    "#Validation data\n",
    "v_size = 2500\n",
    "InputX1v = InputX1_reshape[batch_size:batch_size+v_size,:]\n",
    "InputY1v = InputY1_reshape[batch_size:batch_size+v_size,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bab04556",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "training_iterations = 1000\n",
    "display_iterations = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29c44a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "#Input\n",
    "X = tf.compat.v1.placeholder(tf.float32,shape=(None,Xfeatures))\n",
    "#tf.compat.v1.placeholder(shape=[None, 2], dtype=tf.float32)\n",
    "#Output\n",
    "Y = tf.compat.v1.placeholder(tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9aacb99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neurons\n",
    "L1 = 3\n",
    "L2 = 3\n",
    "L3 = 3\n",
    "\n",
    "#Layer1 weights\n",
    "W_fc1 = tf.Variable(tf.random_uniform([Xfeatures,L1]))\n",
    "b_fc1 = tf.Variable(tf.constant(0.1,shape=[L1]))\n",
    "\n",
    "#Layer2 weights\n",
    "W_fc2 = tf.Variable(tf.random_uniform([L1,L2]))\n",
    "b_fc2 = tf.Variable(tf.constant(0.1,shape=[L2]))\n",
    "\n",
    "#Layer3 weights\n",
    "W_fc3 = tf.Variable(tf.random_uniform([L2,L3]))\n",
    "b_fc3 = tf.Variable(tf.constant(0.1,shape=[L3]))\n",
    "\n",
    "#Output layer weights\n",
    "W_fO= tf.Variable(tf.random_uniform([L3,Yfeatures]))\n",
    "b_fO = tf.Variable(tf.constant(0.1,shape=[Yfeatures]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69ba8219",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Layer 1\n",
    "matmul_fc1=tf.matmul(X, W_fc1) + b_fc1\n",
    "h_fc1 = tf.nn.relu(matmul_fc1)   #ReLU activation\n",
    "#Layer 2\n",
    "matmul_fc2=tf.matmul(h_fc1, W_fc2) + b_fc2\n",
    "h_fc2 = tf.nn.relu(matmul_fc2)   #ReLU activation\n",
    "#Layer 3\n",
    "matmul_fc3=tf.matmul(h_fc2, W_fc3) + b_fc3\n",
    "h_fc3 = tf.nn.relu(matmul_fc3)   #ReLU activation\n",
    "#Output layer\n",
    "matmul_fc4=tf.matmul(h_fc3, W_fO) + b_fO\n",
    "output_layer = matmul_fc4  #linear activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "663f51f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss function\n",
    "mean_square =  tf.reduce_mean(tf.square(Y-output_layer))\n",
    "train_step = tf.train.AdamOptimizer(learning_rate).minimize(mean_square)\n",
    "\n",
    "#Operation to save variables\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2bfd3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: [10.627669]\n",
      "Training loss is: [10.518108] at itertion: 0\n",
      "Validation loss is: [9.021625] at itertion: 0\n",
      "Training loss is: [2.145586] at itertion: 200\n",
      "Validation loss is: [1.4782654] at itertion: 200\n",
      "Training loss is: [1.21938] at itertion: 400\n",
      "Validation loss is: [0.77178305] at itertion: 400\n",
      "Training loss is: [0.9268791] at itertion: 600\n",
      "Validation loss is: [0.4828215] at itertion: 600\n",
      "Training loss is: [0.8183984] at itertion: 800\n",
      "Validation loss is: [0.36056963] at itertion: 800\n",
      "Model saved in file: /tmp/earthquake_model.ckpt\n",
      "Final training loss: [0.77690756]\n",
      "Final validation loss: [0.3126057]\n"
     ]
    }
   ],
   "source": [
    "#Initialization and session\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print(\"Training loss:\",sess.run([mean_square],feed_dict={X:InputX1train,Y:InputY1train}))\n",
    "    for i in range(training_iterations):\n",
    "        sess.run([train_step],feed_dict={X:InputX1train,Y:InputY1train})\n",
    "        if i%display_iterations ==0:\n",
    "            print(\"Training loss is:\",sess.run([mean_square],feed_dict={X:InputX1train,Y:InputY1train}),\"at itertion:\",i)\n",
    "            print(\"Validation loss is:\",sess.run([mean_square],feed_dict={X:InputX1v,Y:InputY1v}),\"at itertion:\",i)\n",
    "    # Save the variables to disk.\n",
    "    save_path = saver.save(sess, \"/tmp/earthquake_model.ckpt\")\n",
    "    print(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "    print(\"Final training loss:\",sess.run([mean_square],feed_dict={X:InputX1train,Y:InputY1train}))\n",
    "    print(\"Final validation loss:\",sess.run([mean_square],feed_dict={X:InputX1v,Y:InputY1v}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ceafb05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Latitude between -90 to 90:10\n",
      "Enter Longitude between -180 to 180:100\n",
      "Enter Depth between 0 to 800:100\n",
      "Enter the number of days:300\n",
      "INFO:tensorflow:Restoring parameters from /tmp/earthquake_model.ckpt\n",
      "Model restored.\n",
      "output: [array([[3.1074939]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "#Testing\n",
    "lat = input(\"Enter Latitude between -90 to 90:\")\n",
    "long = input(\"Enter Longitude between -180 to 180:\")\n",
    "depth = input(\"Enter Depth between 0 to 800:\")\n",
    "days = input(\"Enter the number of days:\")\n",
    "InputX2 = np.asarray([[lat,long,depth,days]],dtype=np.float32)\n",
    "InputX2_norm = (InputX2-X1_min)/(X1_max-X1_min)\n",
    "InputX1test = np.resize(InputX2_norm,(1,Xfeatures))\n",
    "with tf.Session() as sess:\n",
    "    # Restore variables from disk for validation.\n",
    "    saver.restore(sess, \"/tmp/earthquake_model.ckpt\")\n",
    "    print(\"Model restored.\")\n",
    "    #print(\"Final validation loss:\",sess.run([mean_square],feed_dict={X:InputX1v,Y:InputY1v}))\n",
    "    print(\"output:\",sess.run([output_layer],feed_dict={X:InputX1test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553ff3c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
